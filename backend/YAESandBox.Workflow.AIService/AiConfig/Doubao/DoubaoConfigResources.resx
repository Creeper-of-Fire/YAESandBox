<?xml version="1.0" encoding="utf-8"?>
<root>
    <resheader name="resmimetype">
        <value>text/microsoft-resx</value>
    </resheader>
    <resheader name="version">
        <value>2.0</value>
    </resheader>
    <resheader name="reader">
        <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=4.0.0.0, Culture=neutral,
            PublicKeyToken=b77a5c561934e089
        </value>
    </resheader>
    <resheader name="writer">
        <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=4.0.0.0, Culture=neutral,
            PublicKeyToken=b77a5c561934e089
        </value>
    </resheader>

    <!-- DoubaoAiProcessorConfig.ApiKey -->
    <data name="DoubaoAiProcessorConfig_ApiKey_Label" xml:space="preserve">
    <value>API密钥</value>
  </data>
    <data name="DoubaoAiProcessorConfig_ApiKey_Description" xml:space="preserve">
    <value>访问豆包AI服务所需的API密钥。</value>
  </data>
    <data name="DoubaoAiProcessorConfig_ApiKey_Prompt" xml:space="preserve">
    <value>请输入您的豆包API密钥</value>
  </data>

    <!-- DoubaoAiProcessorConfig.ModelName -->
    <data name="DoubaoAiProcessorConfig_ModelName_Label" xml:space="preserve">
    <value>模型名称</value>
  </data>
    <data name="DoubaoAiProcessorConfig_ModelName_Description" xml:space="preserve">
    <value>要使用的豆包AI模型名称，例如 'doubao-pro-32k' 或 'doubao-lite-128k'。</value>
  </data>

    <!-- DoubaoAiProcessorConfig.Temperature -->
    <data name="DoubaoAiProcessorConfig_Temperature_Label" xml:space="preserve">
    <value>温度 (Temperature)</value>
  </data>
    <data name="DoubaoAiProcessorConfig_Temperature_Description" xml:space="preserve">
    <value>控制生成文本的随机性。较低的值（如0.2）使输出更具确定性和重点，较高的值（如0.8）使其更随机。默认值通常为0.7或0.9，具体取决于模型。取值范围一般为 0.0 到 2.0。</value>
  </data>

    <!-- DoubaoAiProcessorConfig.TopP -->
    <data name="DoubaoAiProcessorConfig_TopP_Label" xml:space="preserve">
    <value>Top P采样</value>
  </data>
    <data name="DoubaoAiProcessorConfig_TopP_Description" xml:space="preserve">
      <value>核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。当取值为 0 时模型仅考虑对数概率最大的一个 token。
0.1 意味着只考虑概率质量最高的前 10% 的 token，取值越大生成的随机性越高，取值越低生成的确定性越高。通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.StopSequences -->
    <data name="DoubaoAiProcessorConfig_StopSequences_Label" xml:space="preserve">
    <value>停止序列 (Stop Sequences)</value>
  </data>
    <data name="DoubaoAiProcessorConfig_StopSequences_Description" xml:space="preserve">
      <value>模型遇到该字段所指定的字符串时将停止继续生成，这个词语本身不会输出。最多支持 4 个字符串。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.ResponseFormatType -->
    <data name="DoubaoAiProcessorConfig_ResponseFormatType_Label" xml:space="preserve">
    <value>响应格式类型</value>
  </data>
    <data name="DoubaoAiProcessorConfig_ResponseFormatType_Description" xml:space="preserve">
    <value>指定模型响应的格式。可选值为 "text"（默认）或 "json_object"（强制模型输出有效的JSON对象）。</value>
  </data>

    <!-- DoubaoAiProcessorConfig.FrequencyPenalty -->
    <data name="DoubaoAiProcessorConfig_FrequencyPenalty_Label" xml:space="preserve">
    <value>频率惩罚 (Frequency Penalty)</value>
  </data>
    <data name="DoubaoAiProcessorConfig_FrequencyPenalty_Description" xml:space="preserve">
    <value>根据Token在文本中已出现的频率来惩罚新Token，从而减少逐字重复。正值会降低重复性。取值范围通常在 -2.0 到 2.0 之间。</value>
  </data>

    <!-- DoubaoAiProcessorConfig.PresencePenalty -->
    <data name="DoubaoAiProcessorConfig_PresencePenalty_Label" xml:space="preserve">
    <value>存在惩罚 (Presence Penalty)</value>
  </data>
    <data name="DoubaoAiProcessorConfig_PresencePenalty_Description" xml:space="preserve">
    <value>根据Token是否已在文本中出现至少一次来惩罚新Token，从而鼓励模型引入新的概念和主题。取值范围通常在 -2.0 到 2.0 之间。</value>
  </data>

    <!-- DoubaoAiProcessorConfig.StreamOptions -->
    <data name="DoubaoAiProcessorConfig_StreamOptions_IncludeUsage_Label" xml:space="preserve">
      <value>流式响应选项——token用量</value>
    </data>
    <data name="DoubaoAiProcessorConfig_StreamOptions_IncludeUsage_Description" xml:space="preserve">
      <value>流式调用时，默认不统计 token 用量信息，返回值为null。
如需统计，需设置 stream_options.include_usage为true。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.ServiceTier -->
    <data name="DoubaoAiProcessorConfig_ServiceTier_Label" xml:space="preserve">
    <value>服务等级</value>
  </data>
    <data name="DoubaoAiProcessorConfig_ServiceTier_Description" xml:space="preserve">
      <value>指定是否使用TPM保障包。生效对象为购买了保障包推理接入点。取值范围：
auto：优先使用TPM保障包。如果有TPM保障包额度的推理接入点，本次请求将会使用 TPM 保障包用量，获得更高限流以及响应速度。否则不使用，使用默认的限流和普通的服务响应速度。
default：本次请求，不使用 TPM 保障包，使用默认的限流和普通的服务响应速度，即使请求的是有TPM保障包额度的推理接入点。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.Logprobs -->
    <data name="DoubaoAiProcessorConfig_Logprobs_Label" xml:space="preserve">
    <value>返回Logprobs</value>
  </data>
    <data name="DoubaoAiProcessorConfig_Logprobs_Description" xml:space="preserve">
      <value>是否返回输出 tokens 的对数概率。
false：不返回对数概率信息。
true：返回消息内容中每个输出 token 的对数概率。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.TopLogprobs -->
    <data name="DoubaoAiProcessorConfig_TopLogprobs_Label" xml:space="preserve">
    <value>Top Logprobs数量</value>
  </data>
    <data name="DoubaoAiProcessorConfig_TopLogprobs_Description" xml:space="preserve">
      <value>取值范围为 [0, 20]。
指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 logprobs为true 时可以设置 top_logprobs 参数。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.LogitBias -->
    <data name="DoubaoAiProcessorConfig_LogitBias_Label" xml:space="preserve">
    <value>Logit偏置 (Logit Bias)</value>
  </data>
    <data name="DoubaoAiProcessorConfig_LogitBias_Description" xml:space="preserve">
      <value>调整指定 token 在模型输出内容中出现的概率，使模型生成的内容更加符合特定的偏好。logit_bias 字段接受一个 map 值，其中每个键为词表中的 token ID（使用 tokenization 接口获取），每个值为该 token 的偏差值，取值范围为 [-100, 100]。
-1 会减少选择的可能性，1 会增加选择的可能性；-100 会完全禁止选择该 token，100 会导致仅可选择该 token。该参数的实际效果可能因模型而异。</value>
    </data>

    <!-- DoubaoAiProcessorConfig.Tools -->
</root>